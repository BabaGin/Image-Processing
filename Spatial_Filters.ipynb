{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tc6593H74-IMYrHpyQEHkOnaWjp3ggjy",
      "authorship_tag": "ABX9TyP8mPaZnJn3kZryOFNRG+2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BabaGin/Image-Processing/blob/main/Spatial_Filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 4 - Spatial Filters**"
      ],
      "metadata": {
        "id": "BR4DtiPn9UH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![Mount Drive](https://drive.google.com/uc?id=1yibdRni2VyRt5XOIODRpFURhdVFgYYLB)"
      ],
      "metadata": {
        "id": "EDlZ8SrlI37F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Spatial Filters in Image Processing**\n",
        "---\n",
        "\n",
        "Spatial filters are a fundamental concept in image processing. They are used to modify the spatial characteristics of an image or signal. These filters operate on the pixel values of an image or the samples of a signal in a spatial domain, meaning they consider the values of neighboring pixels or samples to compute the output value for each pixel or sample.\n",
        "\n",
        "Spatial filters are commonly used for various tasks such as image enhancement, noise reduction, edge detection, and feature extraction. They can be broadly categorized into linear and nonlinear filters.\n",
        "\n",
        "1. **Linear Filters**: Linear filters operate on the principle of convolution. They involve a sliding window (also known as a kernel or mask) that moves over the image or signal. At each position, the filter computes the weighted sum of the input values within the window and replaces the center pixel with this sum. Examples of linear filters include Gaussian blur, mean filter, Sobel operator for edge detection, and Laplacian filter.\n",
        "\n",
        "2. **Nonlinear Filters**: Nonlinear filters alter pixel values based on certain criteria without strictly adhering to the convolution principle. They can be used for tasks such as median filtering, which replaces each pixel's value with the median value of neighboring pixels. Nonlinear filters are often preferred for tasks involving noise reduction, as they can better preserve edges and fine details compared to linear filters.\n",
        "\n",
        "Spatial filters play a crucial role in various applications such as image processing, computer vision, medical imaging, remote sensing, and more. They offer versatile tools for manipulating and analyzing spatial data effectively.\n"
      ],
      "metadata": {
        "id": "2mizTCbP9D5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution Operation\n",
        "\n",
        "---\n",
        "\n",
        "The convolution operation in spatial filtering involves applying a filter (also called a kernel or mask) to an input image or signal. The filter is a small matrix of weights, and it is convolved with the input by sliding it over the image or signal and computing the weighted sum of the values under the filter at each position.\n",
        "\n",
        "Here's the formula for the convolution operation:\n",
        "\n",
        "Given:\n",
        "- Input image: $f(x, y)$ where $x$ and $y$ represent the spatial coordinates.\n",
        "- Kernel or filter: $w(i, j)$ where $i$ and $j$ represent the indices of the filter.\n",
        "\n",
        "The convolution operation at a specific position $(x, y)$ is computed as follows:\n",
        "\n",
        "$$\n",
        "(f * w) = \\sum_{i}\\sum_{j} f(x-i, y-j) \\cdot w(i, j)\n",
        "$$\n",
        "\n",
        "In this formula:\n",
        "- $(f * w)$ represents the output value at position $(x, y)$ after convolution.\n",
        "- $f(x-i, y-j)$ represents the pixel value of the input image at position $(x-i, y-j)$.\n",
        "- $w(i, j)$ represents the weight of the filter at position $(i, j)$.\n",
        "- The summation is taken over all possible values of $i$ and $j$ within the filter dimensions.\n",
        "\n",
        "In practical implementations, the filter is applied by centering it at each pixel position of the input image, and the output value is computed by taking the weighted sum of the overlapping pixel values and filter weights.\n",
        "\n",
        "It's worth noting that depending on the boundary conditions (e.g., zero-padding, mirror-padding, wrap-around), the convolution operation might produce different results at the image boundaries.\n",
        "\n",
        "---\n",
        "<center>\n",
        "    <img src=\"https://static1.squarespace.com/static/5a8dbb09bff2006c33266320/t/5baff4441905f4c995f31810/1538257990895/\" />\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "t8mi-OLqbsHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to download images for this tutorial purposes.\n",
        "\n",
        "- *Note that this code will save the images temporarily in your working directory. Always check your image path when you want to load an image*"
      ],
      "metadata": {
        "id": "sY1QyJaCvB1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/BabaGin/Image-Processing/main/sample%20images/steam-train.jpeg\n",
        "!wget https://raw.githubusercontent.com/BabaGin/Image-Processing/main/sample%20images/kawaii.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYXai1QrmYuO",
        "outputId": "dcabd885-0c74-4426-9891-3baec4febd6b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-05 14:48:34--  https://raw.githubusercontent.com/BabaGin/Image-Processing/main/sample%20images/steam-train.jpeg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405529 (396K) [image/jpeg]\n",
            "Saving to: ‘steam-train.jpeg’\n",
            "\n",
            "\rsteam-train.jpeg      0%[                    ]       0  --.-KB/s               \rsteam-train.jpeg    100%[===================>] 396.02K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-05 14:48:34 (11.0 MB/s) - ‘steam-train.jpeg’ saved [405529/405529]\n",
            "\n",
            "--2024-04-05 14:48:34--  https://raw.githubusercontent.com/BabaGin/Image-Processing/main/sample%20images/kawaii.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 493624 (482K) [image/png]\n",
            "Saving to: ‘kawaii.png’\n",
            "\n",
            "kawaii.png          100%[===================>] 482.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-05 14:48:35 (12.6 MB/s) - ‘kawaii.png’ saved [493624/493624]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required packages for image filtering."
      ],
      "metadata": {
        "id": "oxQCO3ngzIkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "KT7_P9k9zLG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to display two images next to each other."
      ],
      "metadata": {
        "id": "RJc7E41i6Lpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_2image(image_1, image_2,title_1=\"Orignal\",title_2=\"New Image\"):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title_1)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title_2)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "38Oq8Ioq6Kn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to display three consecutive images in a row."
      ],
      "metadata": {
        "id": "2n29GpII_p8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_3image(image_1, image_2, image_3, title_1=\"Orignal\",title_2=\"New Image1\", title_3=\"New Image2\"):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title_1)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title_2)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(cv2.cvtColor(image_3, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title_3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "83OXrdp1_XAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Filtering\n",
        "---\n",
        "Filtering is a process aimed at improving an image, such as eliminating noise present in it, which can result from poor camera quality or inefficient image compression techniques. These factors contributing to noise can also lead to blurry images, but filters can be applied to enhance the sharpness of such images. Convolution serves as a common method for image filtering, where the filter, referred to as the kernel, is pivotal, each serving specific functions. Moreover, convolution finds extensive applications in advanced artificial intelligence algorithms. The procedure involves computing the dot product between the kernel and a corresponding portion of the image, with subsequent shifting of the kernel and repeating the process.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0l9aAORAeq-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Noise\n",
        "\n",
        "The following code shows how to add *white noise* to the image:\n",
        "\n",
        "```python\n",
        "#Adding zero means white noise to the image\n",
        "# Loads the image from the specified file\n",
        "image = cv2.imread('path_to_image_file')\n",
        "# Get the number of rows and columns in the image\n",
        "rows, cols,_= image.shape\n",
        "# Creates values using a normal distribution with a mean of 0 and standard deviation of 10, the values are converted to unit8 which means the values are between 0 and 255\n",
        "mean = 0\n",
        "sigma = 10\n",
        "noise = np.random.normal(mean,sigma,(rows,cols,3)).astype(np.uint8)\n",
        "# Add the noise to the image\n",
        "w_noise = image + noise\n",
        "\n",
        "```\n",
        "The code below displays how to add *salt and pepper noise* to the image:\n",
        "\n",
        "```python\n",
        "s_and_p = np.random.rand(image.shape[0], image.shape[1])\n",
        "\n",
        "# if we consider 5% salt and pepper noise, we'd like to have\n",
        "# 2.5% salt and 2.5% pepper. thus:\n",
        "salt = s_and_p > .975\n",
        "pepper = s_and_p < .025\n",
        "\n",
        "# in order to add some noise, we should turn off black (pepper) locations and\n",
        "# turn on white (white) locations.\n",
        "channel_2 = np.atleast_1d(image[:, :, 1])\n",
        "snp_noisy = np.zeros_like(channel_2)\n",
        "\n",
        "for i in range(channel_2.shape[0]*channel_2.shape[1]):\n",
        "  if salt.ravel()[i] == 1:\n",
        "    snp_noisy.ravel()[i] = 255\n",
        "  elif pepper.ravel()[i] == 1:\n",
        "    snp_noisy.ravel()[i] = 0\n",
        "  else:\n",
        "    snp_noisy.ravel()[i] = channel_2.ravel()[i]\n",
        "```\n"
      ],
      "metadata": {
        "id": "CnP7KWHNNA8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1\n",
        " Load the `steam-train.jpeg` image file and add white noise with a mean of 0 and standard deviation of 15. Plots the original image and the noisy image using the function defined at the top"
      ],
      "metadata": {
        "id": "BJuWOwL6fPGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "KZ4ayJt3fOkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load the `kawaii.png` image file and add 5% salt and pepper noise to the original image. Plots the original image and the noisy image using the function defined at the top"
      ],
      "metadata": {
        "id": "hzbYo3bcPqv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "9rwpH-sbPrO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging Filter\n",
        "\n",
        "Smoothing filters work by averaging the pixel values within a local area, often referred to as a neighborhood. These filters are also known as low-pass filters since they reduce high-frequency components in the image. In mean filtering, the kernel simply computes the average of the pixel values within the neighborhood.\n",
        "\n",
        "Here is how we create a 3 by 3 averaging kernel:\n",
        "\n",
        "```python\n",
        "# Create a kernel which is a 3 by 3 array\n",
        "kernel = np.ones((3,3),np.float32)/9\n",
        "# Filters the images using the kernel\n",
        "image_filtered = cv2.filter2D(src=noisy_image, ddepth=-1, kernel=kernel)\n",
        "\n",
        "```\n",
        "\n",
        "The function <code>filter2D</code> performs 2D convolution between the image <code>src</code> and the  <code>kernel</code> on each color channel independently. The parameter <a href=\"https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2022-01-01#filter_depths\">ddepth</a> has to do with the size of the output image, we will set it to -1 so the input and output are the same size.\n",
        "\n",
        "The complete command for performing 2D spatial filter over images in OpenCV is cv2.filter2D with the following list of parameters. Some of the parameters are not necessarily used.\n",
        "\n",
        "<code>cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]])</code>\n",
        "\n",
        "<code>src</code> – input image.\n",
        "\n",
        "<code>ddepth</code> –\n",
        "desired depth of the destination image; if it is negative, it will be the same as <code>src.depth()</code>; the following combinations of <code>src.depth()</code> and ddepth are supported:\n",
        "\n",
        "<code>src.depth() = CV_8U, ddepth = -1/CV_16S/CV_32F/CV_64F</code>\n",
        "\n",
        "<code>src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F</code>\n",
        "\n",
        "<code>src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F</code>\n",
        "\n",
        "<code>src.depth() = CV_64F, ddepth = -1/CV_64F</code>\n",
        "\n",
        "<code>kernel</code> – convolution kernel (or rather a correlation kernel), a single-channel floating point matrix; if you want to apply different kernels to different channels, split the image into separate color planes using <code>split()</code> and process them individually.\n",
        "\n",
        "<code>anchor</code> – anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center.\n",
        "\n",
        "_The anchor can be replaced by a single -1, indicating that the center of the kernel is on its middle pixel._\n",
        "\n",
        "<code>delta</code> – optional value added to the filtered pixels before storing them in dst.\n",
        "\n",
        "<code>borderType</code> – pixel extrapolation method (see [borderInterpolate()](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#int%20borderInterpolate(int%20p,%20int%20len,%20int%20borderType) for details).\n",
        "\n",
        "Another simple way to apply a simple averaging filter is to use `cv2.blur()` function. The function can be applied as below:\n",
        "```python\n",
        "# you can check the docs for further information.\n",
        "blurred_image = cv2.blur(src, (3, 3), ddepth)\n",
        "```\n",
        "\n",
        "*It is important to note that a smaller kernel keeps the image sharp, but filters less noise*"
      ],
      "metadata": {
        "id": "U6Po_XVBABV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2\n",
        " Define a 5x5 averaging kernel by using numpy and apply that filter to kawaii image which consist of salt and pepper noise that you've been created from *Exercise 1*. Plot those 2 images using `plot_2image()` function as \"Noisy Image\" and \"Blurred Image\""
      ],
      "metadata": {
        "id": "31nNpyOQkGfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "ja1oSdAtkdKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3\n",
        "Define two averaging kernels, 5x5 and 7x7, respectively by using numpy. Apply those filters to salt and pepper noise image that you've been created from Exercise 1. Plot those 3 images using `plot_3image()` function as \"Noisy Image\", \"5x5 Filter\", and \"7x7 Filter\". Analyze the difference."
      ],
      "metadata": {
        "id": "IdjCQszGI66V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "itDoXAO-K5dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian Blur\n",
        "\n",
        "Gaussian blur is a common image processing technique used for smoothing or blurring images. It applies a convolution operation using a Gaussian kernel to the input image. The Gaussian kernel is a two-dimensional matrix that represents a bell-shaped curve, with higher weights assigned to the central elements and decreasing weights as you move away from the center.\n",
        "\n",
        "Applying a Gaussian blur to an image effectively reduces high-frequency noise and details, resulting in a smoother appearance. It is often used as a preprocessing step in image processing tasks such as noise reduction, edge detection, and feature extraction.\n",
        "\n",
        "Mathematically, the Gaussian blur operation can be represented by convolving the input image with the Gaussian kernel. The size of the kernel (often referred to as the \"sigma\" parameter) determines the extent of blurring applied to the image. Larger kernel sizes result in more significant blurring.\n",
        "\n",
        "```python\n",
        "gaus_filter = cv2.GaussianBlur(src,(ksize.width, ksize.height),sigmaX,sigmaY)\n",
        "```\n",
        "\n",
        "Parameters:\n",
        "\n",
        "<p><code>src</code> input image; the image can have any number of channels, which are processed independently</p>\n",
        "<p><code>ksize:</code> Gaussian kernel size</p>\n",
        "<p><code>sigmaX</code> Gaussian kernel standard deviation in the X direction</p>\n",
        "<p><code>sigmaY</code> Gaussian kernel standard deviation in the Y direction; if sigmaY is zero, it is set to be equal to sigmaX </p>\n",
        "\n"
      ],
      "metadata": {
        "id": "OES3v6hCcX2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4\n",
        "Load any image that you want and add some noise on it.\n",
        "1. Apply the noisy image with Gaussian filter using following parameters:\n",
        "<p><code>ksize:</code> 5x5</p>\n",
        "<p><code>sigmaX:</code> 10</p>\n",
        "<p><code>sigmaY:</code> 10 </p>\n",
        "\n",
        "2. Apply the noisy image with non-squared Gaussian kernel using following parameters:\n",
        "<p><code>ksize:</code> 7x11</p>\n",
        "<p><code>sigmaX:</code> 20</p>\n",
        "<p><code>sigmaY:</code> 20</p>\n",
        "\n",
        "Plot all those images in one figure. Analyze the output images."
      ],
      "metadata": {
        "id": "R05JUhFaejP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Sharpening\n",
        "Image sharpening can indeed be achieved by applying a specific kernel to the image. Commonly used kernels for sharpening are the high-pass filter kernel and Laplacian kernel. The Laplacian operator calculates the second derivative of the image, which highlights regions of rapid intensity change, such as edges.\n",
        "\n",
        "High-pass filter kernel:\n",
        "\n",
        "$$\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 9 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$$\n",
        "\n",
        "Laplacian kernel:\n",
        "\n",
        "$$\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 4 & -1 \\\\ 0 & -1 & 0 \\end{bmatrix}$$\n",
        "\n",
        "```python\n",
        "# Common Kernel for image sharpening\n",
        "hpf_kernel = np.array([[-1,-1,-1],\n",
        "                   [-1, 9,-1],\n",
        "                   [-1,-1,-1]])\n",
        "\n",
        "laplace_kernel = np.array([[0,-1,0],\n",
        "                   [-1, 4,-1],\n",
        "                   [0,-1,0]])\n",
        "# Applys the sharpening filter using kernel on the original image without noise\n",
        "sharpened = cv2.filter2D(image, -1, kernel)\n",
        "```"
      ],
      "metadata": {
        "id": "H36NLDowhL5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5\n",
        "Load any image and apply high-pass filter kernel and laplacian kernel to the original image. Plot in one figure."
      ],
      "metadata": {
        "id": "8gAvM7RBu5wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "squY9_VGehXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Edges\n",
        "\n",
        "Edges occur where there is a transition in pixel intensities. The gradient of a function provides information about the rate of change. We can estimate the gradient of a grayscale image using convolution. There are various techniques for approximating the gradient, and one commonly used method is the Sobel edge detector. This technique involves performing multiple convolutions and then determining the magnitude of the resulting gradient. Let's examine the following code as an example.\n",
        "\n",
        "\n",
        "```python\n",
        "# Loads the image from the specified file\n",
        "img_gray = cv2.imread('path_to_image_file', cv2.IMREAD_GRAYSCALE)\n",
        "print(img_gray)\n",
        "# Renders the image from the array of data, notice how it is 2 diemensional instead of 3 diemensional because it has no color\n",
        "plt.imshow(img_gray ,cmap='gray')\n",
        "```\n",
        "\n",
        "Then, apply smoothing to the image, which reduces variations that could be introduced by noise, thereby minimizing its impact on the gradient.We apply smoothing to the image, which reduces variations that could be introduced by noise, thereby minimizing its impact on the gradient.\n",
        "```python\n",
        "# Filters the images using GaussianBlur on the image with noise using a 3 by 3 kernel\n",
        "img_gray = cv2.GaussianBlur(img_gray,(3,3),sigmaX=0.1,sigmaY=0.1)\n",
        "# Renders the filtered image\n",
        "plt.imshow(img_gray ,cmap='gray')\n",
        "```\n",
        "\n",
        "We can approximate the derivative in the X or Y direction  using the <code>Sobel</code> function, here are the parameters:\n",
        "\n",
        "<p><code>src</code>: input image</p>\n",
        "<p><code>ddepth</code>: output image depth, see combinations; in the case of 8-bit input images it will result in truncated derivatives</p>\n",
        "<p><code>dx</code>: order of the derivative x</p>\n",
        "<p><code>dx</code>: order of the derivative y</p>\n",
        "<p><code>ksize</code> size of the extended Sobel kernel; it must be 1, 3, 5, or 7</p>\n",
        "\n",
        "$dx$ = 1 represents the derivative in the x-direction.  The function approximates  the derivative by  convolving   the image with the following kernel:  \n",
        "\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\\\\\n",
        "2 & 0 & -2 \\\\\\\\\n",
        "1 & 0 & -1\n",
        "\\end{bmatrix}\n",
        "\n",
        "$dy$ = 1 represents the derivative in the y-direction.  The function approximates  the derivative by  convolving   the image with the following kernel:\n",
        "\n",
        "\\begin{bmatrix}\n",
        "\\ \\ 1 & \\ \\ 2 & \\ \\ 1 \\\\\\\\\n",
        "\\ \\ 0 & \\ \\ 0 & \\ \\ 0 \\\\\\\\\n",
        "-1 & -2 & -1\n",
        "\\end{bmatrix}\n",
        "\n",
        "```python\n",
        "ddepth = cv2.CV_16S\n",
        "\n",
        "# Applys the filter on the image in the X direction\n",
        "grad_x = cv2.Sobel(src=img_gray, ddepth=ddepth, dx=1, dy=0, ksize=3)\n",
        "plt.imshow(grad_x,cmap='gray')\n",
        "\n",
        "# Applys the filter on the image in the X direction\n",
        "grad_y = cv2.Sobel(src=img_gray, ddepth=ddepth, dx=0, dy=1, ksize=3)\n",
        "plt.imshow(grad_y,cmap='gray')\n",
        "```\n",
        "We can approximate the gradient by calculating absolute values, and converts the result to 8-bit:\n",
        "```python\n",
        "# Converts the values back to a number between 0 and 255\n",
        "abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
        "abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
        "\n",
        "# Adds the derivative in the X and Y direction\n",
        "grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grad,cmap='gray')\n",
        "```\n"
      ],
      "metadata": {
        "id": "Mkbtl_81BAnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6\n",
        "\n",
        "Load any image and apply Sobel kenels in X and Y directions. Plot input and output images in one figure."
      ],
      "metadata": {
        "id": "VWLYSfIbBe86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "xWuRSXKmA-u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7\n",
        "\n",
        "By using same image as in *Exercise 4* apply vertical kernel of the following matrix to your original image. Plot input and output images in one figure.\n",
        "\n",
        "$$\\begin{bmatrix} 1 & 0 & -1 \\\\ 1 & 0 & -1 \\\\ 1 & 0 & -1 \\end{bmatrix}$$\n",
        "\n",
        "```python\n",
        "# vertical gradient kernel\n",
        "# define a random kernel\n",
        "vertical_gd = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
        "\n",
        "# apply vertical kernel\n",
        "filter_v = cv2.filter2D(image[:, :, 2], -1, vertical_gd)\n",
        "```"
      ],
      "metadata": {
        "id": "DhlwRi_8DMHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n",
        "\n"
      ],
      "metadata": {
        "id": "C2Y_qp0bDelu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Median\n",
        "\n",
        "Median filters identify the median value among all the pixels within the kernel region, and then substitute the central element with this calculated median value.\n",
        "\n",
        "```python\n",
        "# Load the input image\n",
        "image = cv2.imread(\"path_to_image_file\",cv2.IMREAD_GRAYSCALE)\n",
        "# Make the image larger when it renders\n",
        "plt.figure(figsize=(10,10))\n",
        "# Renders the image\n",
        "plt.imshow(image,cmap=\"gray\")\n",
        "```\n",
        "Now let's apply a Median Filter by using the `medianBlur` function. The parameters for this function are `src`: The image and `ksize`: Kernel size\n",
        "\n",
        "```python\n",
        "# Filter the image using Median Blur with a kernel of size 5\n",
        "filtered_image = cv2.medianBlur(image, 5)\n",
        "# Make the image larger when it renders\n",
        "plt.figure(figsize=(10,10))\n",
        "# Renders the image\n",
        "plt.imshow(filtered_image,cmap=\"gray\")\n",
        "```"
      ],
      "metadata": {
        "id": "DelkekDMGLnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Function Parameters\n",
        "\n",
        "`src`: The image to use\n",
        "`thresh`: The threshold\n",
        "`maxval`: The maxval to use\n",
        "`type`: Type of filtering\n",
        "\n",
        "The threshold function works by looking at each pixel's grayscale value and assigning a value if it is below the threshold and another value if it is above the threshold. In our example the threshold is 0 (black) and the type is binary inverse so if a value is above the threshold the assigned value is 0 (black) and if it is below or equals the threshold the maxval 255 (white) is used. So if the pixel is 0 black it is assigned 255 (white) and if the pixel is not black then it is assigned black which is what THRESH_BINARY_INV tells OpenCV to do. This is how it would work without THRESH_OTSU.\n",
        "\n",
        "Since we are using THRESH_OTSU it means that OpenCV will decide an optimal threshold. In our example below the threshold, we provide does not get used in the filter OpenCV will use an optimal one.\n",
        "\n",
        "```python\n",
        "# Returns ret which is the threshold used and outs which is the image\n",
        "ret, outs = cv2.threshold(src = image, thresh = 0, maxval = 255, type = cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Make the image larger when it renders\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# Render the image\n",
        "plt.imshow(outs, cmap='gray')\n",
        "```"
      ],
      "metadata": {
        "id": "pKlVFlMT1OfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 8\n",
        "Load `kawaii.png` image file add salt and pepper noise and apply median filter using given tutorial."
      ],
      "metadata": {
        "id": "5IfqTTW21uMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "RuQ31ZaRF8hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus Tutorial\n",
        "\n",
        "**Padding**\n",
        "---\n",
        "Understanding how to handle border values when applying a filter to an image is crucial. When parts of the filter extend beyond the image border, it's essential to know how to handle this situation. The \"_borderType_\" parameter manages this functionality of filters. Typically, this function isn't called directly.\n",
        "\n",
        "It is used inside [FilterEngine](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#FilterEngine) and [copyMakeBorder()](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#void%20copyMakeBorder(InputArray%20src,%20OutputArray%20dst,%20int%20top,%20int%20bottom,%20int%20left,%20int%20right,%20int%20borderType,%20const%20Scalar&%20value) to compute tables for quick extrapolation. It means that we should first create the bordered (padded) image and then apply the filter over that image instead of the original image.\n",
        "\n",
        "Various border types, image boundaries, are denoted with '|'\n",
        "\n",
        "* <code>BORDER_REPLICATE</code>:    **aaaaaa|abcdefgh|hhhhhhh**\n",
        "* <code>BORDER_REFLECT</code>:       **fedcba|abcdefgh|hgfedcb**\n",
        "* <code>BORDER_REFLECT_101</code>:   **gfedcb|abcdefgh|gfedcba**\n",
        "* <code>BORDER_WRAP</code>:          **cdefgh|abcdefgh|abcdefg**\n",
        "* <code>BORDER_CONSTANT</code>:      **iiiiii|abcdefgh|iiiiiii**  with some specified 'i'\n",
        "\n",
        "To generate an image with borders, the following command and its parameters are utilized. This command allows for the insertion of distinct border sizes on each side of the image.\n",
        "\n",
        "```python\n",
        "cv2.copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value]])\n",
        "```\n",
        "\n",
        "Where:\n",
        "\n",
        "- **src**: Represents the source image.\n",
        "\n",
        "- **Size(src.cols+left+right, src.rows+top+bottom)**: Specifies the size of the output image considering the additional border sizes.\n",
        "\n",
        "- **top, bottom, left, right**: Parameters that determine the number of pixels to extend the source image rectangle in each direction. For instance, if `top=1, bottom=1, left=1, right=1`, a 1-pixel-wide border will be created.\n",
        "\n",
        "- **borderType**: Denotes the type of border, chosen from the declared border types.\n",
        "\n",
        "- **value**: Signifies the border value when `borderType==BORDER_CONSTANT`.\n",
        "\n",
        "The following code is how to add padding with various borders.\n",
        "\n",
        "```python\n",
        "img_bdr_wrap = cv2.copyMakeBorder(image, top, bottom, left, right,\n",
        "                          cv2.BORDER_WRAP)\n",
        "img_bdr_reflect = cv2.copyMakeBorder(image, top, bottom, left, right,\n",
        "                          cv2.BORDER_REFLECT)\n",
        "img_bdr_replicate = cv2.copyMakeBorder(image, top, bottom, left, right,\n",
        "                          cv2.BORDER_REPLICATE)\n",
        "img_bdr_constant = cv2.copyMakeBorder(image, top, bottom, left, right,\n",
        "                          cv2.BORDER_CONSTANT, const)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Bonus Exercise\n",
        "Load the `steam-train.jpeg` image file and apply four different border `BORDER_WRAP`, `BORDER_REFLECT`, `BORDER_REPLICATE`, `BORDER_CONSTANT`, respectively.\n",
        "Use these parameters as args for your code `top = 30; bottom = 30; left = 30; right = 30;\n",
        "const = 100`\n",
        "Plot as in one figure with 2 by 2 grid.\n",
        "\n",
        "---\n",
        "**Expected Output:**\n",
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?id=15ubWqgs2mBOC_armPREk38_-me3OIxmB\" alt=\"centered image\" />\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "-apIx2hcqKsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Type your code here:\n"
      ],
      "metadata": {
        "id": "rUhAVETMuvHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you for completing this tutorial!\n",
        "\n",
        "\n",
        "## Author\n",
        "\n",
        "Ginanjar Suwasono Adi\n",
        "\n",
        "## <h3 align=\"center\"> © AIoT Research Group 2024. All rights reserved. <h3/>"
      ],
      "metadata": {
        "id": "jr2o1pSq0FgQ"
      }
    }
  ]
}